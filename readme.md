# Bulk Elasticsearch Uploader

Este script permite cargar en masa documentos a un √≠ndice de Elasticsearch utilizando un archivo JSON como fuente. Los datos se dividen en paquetes y se suben de forma asincr√≥nica.

## üöÄ Caracter√≠sticas

- Lectura de datos desde un archivo JSON.
- Divisi√≥n en paquetes para cargas por lotes.
- Subida a Elasticsearch utilizando `fetch` con autenticaci√≥n por API Key.
- Registro de elementos que no pudieron subirse.
- Uso de variables de entorno para mantener configuraciones sensibles fuera del c√≥digo.

## üì¶ Requisitos

- Node.js >= 18
- Elasticsearch accesible mediante HTTP
- Archivo `.env` con la configuraci√≥n requerida

## üìÅ Estructura esperada del archivo de datos

El archivo JSON debe contener un array de objetos, por ejemplo:

```json
[
  { "id": 1, "name": "Item 1" },
  { "id": 2, "name": "Item 2" }
]
````

## ‚öôÔ∏è Configuraci√≥n

Crea un archivo `.env` en la ra√≠z del proyecto basado en este ejemplo:

```env
FILE=./data.json
HOST=http://localhost:9200
INDEX_NAME=my-index
API_KEY=your-api-key
PACKAGES_SIZE=500
```

### Variables

* `FILE`: Ruta al archivo `.json` con los datos.
* `HOST`: URL del host de Elasticsearch.
* `INDEX_NAME`: Nombre del √≠ndice en Elasticsearch.
* `API_KEY`: Clave de autenticaci√≥n para Elasticsearch.
* `PACKAGES_SIZE`: Cantidad de elementos por paquete (por defecto: 500).

## ‚ñ∂Ô∏è C√≥mo ejecutar

Ejecuta el script con Node.js:

```bash
node script.js
```

El script te pedir√° confirmaci√≥n antes de iniciar el proceso.

## üêû Errores

Todos los elementos que no pudieron subirse correctamente se guardar√°n en el archivo `not_uploaded.json` al final del proceso.

## üìÑ Licencia

MIT ‚Äî Libre uso, modificaci√≥n y distribuci√≥n.

---
**Nota:** Aseg√∫rate de no subir tu archivo `.env` a repositorios p√∫blicos. Agrega `.env` a tu `.gitignore`.